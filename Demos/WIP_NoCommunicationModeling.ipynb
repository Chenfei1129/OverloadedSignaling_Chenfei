{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-08T23:50:03.342537Z",
     "start_time": "2019-10-08T23:50:03.179718Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-08T23:50:06.188156Z",
     "start_time": "2019-10-08T23:50:06.180433Z"
    }
   },
   "outputs": [],
   "source": [
    "def getWorldSpace(wall, nBoxes, nRewards): #omega world, list output\n",
    "    if wall:\n",
    "        possibleWorlds = [w for w in itertools.product([1,0], repeat = nBoxes)] \n",
    "    else:\n",
    "        possibleWorlds = [w for w in itertools.product([1,0], repeat = nBoxes) if list(w).count(1) == nRewards]\n",
    "    return(possibleWorlds)\n",
    "\n",
    "def getActionSpace(nBoxes, nReceiverChoices): #omega actions, list output\n",
    "    possibleActions = [a for a in itertools.product([1,0], repeat = nBoxes) \n",
    "                       if sum(a) <= nReceiverChoices]\n",
    "    return(possibleActions)\n",
    "\n",
    "def getSignalSpace(nBoxes, nSignals): #omega singals, list output\n",
    "    all_utterances = [c for c in itertools.product([1,0], repeat = nBoxes) \n",
    "                      if (sum(c) <= nSignals)] \n",
    "    return(all_utterances)\n",
    "\n",
    "# Misyak - returns a boolean of whether the input signal is possible given the mind and signal category\n",
    "def signalIsConsistent_Boxes(signal, mind, signalType, goToSignal = '1'):\n",
    "    world = mind['worlds']\n",
    "    signalTypeStr = str(signalType)\n",
    "    \n",
    "    if signalTypeStr == goToSignal:\n",
    "        consistentSignals = [int(w == 1) for u, w in zip(signal, world) if u == 1]  \n",
    "    else:\n",
    "        consistentSignals = [int(w != 1) for u, w in zip(signal, world) if u == 1]\n",
    "    return(consistentSignals.count(0) == 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-08T23:49:54.252102Z",
     "start_time": "2019-10-08T23:49:54.245049Z"
    }
   },
   "outputs": [],
   "source": [
    "#mind generation (pdf over set of possible target minds)- specify each mind component function and combine for the full mind distribution\n",
    "class GenerateMind(object):\n",
    "    def __init__(self, getWorldProbability, getDesireProbability, getGoalProbability):\n",
    "        self.getWorldProbability = getWorldProbability\n",
    "        self.getDesireProbability = getDesireProbability\n",
    "        self.getGoalProbability = getGoalProbability\n",
    "        self.mindProbabilityLabel = 'p(mind)'\n",
    "        \n",
    "    def __call__(self, mindSpaceDictionary):\n",
    "        jointMindSpace = getMultiIndexMindSpace(mindSpaceDictionary)\n",
    "        getMindForCondition = lambda x: self.getConditionMind(x, mindSpaceDictionary)\n",
    "        mindProbabilitySeries = jointMindSpace.groupby(jointMindSpace.index.names).apply(lambda x: self.getConditionMind(x, mindSpaceDictionary))\n",
    "        mindProbability = pd.DataFrame(normalizeValuesPdSeries(mindProbabilitySeries))\n",
    "        mindProbability.rename(columns={0 : self.mindProbabilityLabel}, inplace=True)\n",
    "        return(mindProbability)\n",
    "    \n",
    "    def getConditionMind(self, oneMindCondition, mindSpace):\n",
    "        world = oneMindCondition.index.get_level_values('worlds')[0]\n",
    "        desire = oneMindCondition.index.get_level_values('desires')[0]\n",
    "        goal = oneMindCondition.index.get_level_values('goals')[0]\n",
    "        \n",
    "        worldSpace = mindSpace['worlds']\n",
    "        worldPDF = self.getWorldProbability(worldSpace)\n",
    "        \n",
    "        desireSpace = mindSpace['desires']\n",
    "        desirePDF = self.getDesireProbability(desireSpace)\n",
    "        \n",
    "        goalSpace = mindSpace['goals']\n",
    "        conditionalGoalPDF = self.getGoalProbability(goalSpace, world, desire)\n",
    "\n",
    "        mindProbability = worldPDF.loc[world].values[0]*desirePDF.loc[desire].values[0]*conditionalGoalPDF.loc[goal].values[0]\n",
    "        \n",
    "        if type(mindProbability) != float:\n",
    "            mindProbability = mindProbability[0]\n",
    "        return(mindProbability)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-08T23:50:08.968093Z",
     "start_time": "2019-10-08T23:50:08.942629Z"
    }
   },
   "outputs": [],
   "source": [
    "#helper functions for pandas\n",
    "def getMultiIndexMindSpace(mindLevelsDictionary):\n",
    "    conditions = list(mindLevelsDictionary.keys())\n",
    "    levelValues = list(mindLevelsDictionary.values())\n",
    "    speakerMindIndex = pd.MultiIndex.from_product(levelValues, names=conditions)\n",
    "    jointMind = pd.DataFrame(index=speakerMindIndex)\n",
    "    return(jointMind)\n",
    "\n",
    "def normalizeValuesPdSeries(pandasSeries):\n",
    "    totalSum = sum(pandasSeries)\n",
    "    probabilities = pandasSeries.groupby(pandasSeries.index.names).apply(lambda x: x/totalSum)\n",
    "    return(probabilities)\n",
    "    \n",
    "# P(w) component of the mind - uniform distribution \n",
    "def getWorldProbabiltiy_Uniform(worldSpace):\n",
    "    worldDict = {'worlds': worldSpace}\n",
    "    worldSpaceDF = getMultiIndexMindSpace(worldDict)\n",
    "    worldSpaceDF = worldSpaceDF.loc[~worldSpaceDF.index.duplicated(keep='first')]\n",
    "\n",
    "    numberOfWorlds = len(worldSpace)\n",
    "    getConditionWorldProbabiltiy = lambda x: 1.0/numberOfWorlds\n",
    "    worldProbabilities = worldSpaceDF.groupby(worldSpaceDF.index.names).apply(getConditionWorldProbabiltiy)\n",
    "    worldSpaceDF['p(w)'] = worldSpaceDF.index.get_level_values(0).map(normalizeValuesPdSeries(worldProbabilities).get)\n",
    "    return(worldSpaceDF)\n",
    "\n",
    "# p(d) component of the mind - uniform distribution\n",
    "def getDesireProbability_Uniform(desireSpace):\n",
    "    desireDict = {'desires': desireSpace}\n",
    "    desireSpaceDF = getMultiIndexMindSpace(desireDict)\n",
    "\n",
    "    getConditionDesireProbability = lambda x: 1.0/len(desireSpace)\n",
    "    desireProbabilities = desireSpaceDF.groupby(desireSpaceDF.index.names).apply(getConditionDesireProbability)\n",
    "    desireSpaceDF['p(d)'] = desireSpaceDF.index.get_level_values(0).map(normalizeValuesPdSeries(desireProbabilities).get)\n",
    "    return(desireSpaceDF)\n",
    "\n",
    "#p(g|w,d) component of the mind\n",
    "\n",
    "#single goal case - bananas in boxes Misyak\n",
    "def getGoalGivenWorldAndDesire_SingleGoal(goalSpace, world, desire):\n",
    "    goalDict = {'goals': goalSpace}\n",
    "    goalSpaceDF = getMultiIndexMindSpace(goalDict)\n",
    "\n",
    "    goalProbabilities = goalSpaceDF.groupby(goalSpaceDF.index.names).apply(lambda x: 1.0)\n",
    "    goalSpaceDF['p(g|w,d)'] = goalSpaceDF.index.get_level_values(0).map(normalizeValuesPdSeries(goalProbabilities).get)\n",
    "    return(goalSpaceDF)\n",
    "\n",
    "#multiple goal - Grosse battery example, uniform\n",
    "def getGoalGivenWorldAndDesire_Grosse(goalSpace, world, desire, goalProbabilities = None):\n",
    "    goalDict = {'goals': goalSpace}\n",
    "    goalSpaceDF = getMultiIndexMindSpace(goalDict)\n",
    "    \n",
    "    goalProbabilities = goalSpaceDF.groupby(goalSpaceDF.index.names).apply(lambda x: getConditionGoalPDF_Grosse(goal = x.index.get_level_values('goals')[0], world = world))\n",
    "    goalSpaceDF['p(g|w,d)'] = goalSpaceDF.index.get_level_values(0).map(normalizeValuesPdSeries(goalProbabilities).get)\n",
    "    return(goalSpaceDF)\n",
    "\n",
    "def getConditionGoalPDF_Grosse(goal, world, nullWorld = 'n', nullGoal = 'n'):\n",
    "    if nullWorld in world:\n",
    "        assert world == nullWorld, 'incongruous world: cannot have neither battery and a battery value in the world'\n",
    "    if nullGoal in goal:\n",
    "        assert goal == nullGoal, \"incongruous goal: cannot have both neither battery and a battery value as a goal\"\n",
    "        return(1)\n",
    "    return(int(all(g in world for g in goal)))\n",
    "\n",
    "\n",
    "\n",
    "# utility of action U(a,w,g) - misyak\n",
    "\"\"\"\n",
    "    costOfLocation: int/float or iterable. If int, a fixed cost associated with the number of actions taken. If iterable, the cost of each action in each location\n",
    "    valueOfReward = int/float. The value of each reward an action taken receives\n",
    "    costOfNonReward = int/float. The cost associated with each locaiton action that does not result in reward\n",
    "\"\"\"\n",
    "class ActionUtility(object):\n",
    "    def __init__(self, costOfLocation, valueOfReward, costOfNonReward):\n",
    "        self.costOfLocation = costOfLocation\n",
    "        self.valueOfReward = valueOfReward\n",
    "        self.costOfNonReward = costOfNonReward\n",
    "\n",
    "    def __call__(self, action, world, goal=None):\n",
    "        numberOfLocationsInWorld = len(world)\n",
    "        locationActionCost = self.getLocationCostList(numberOfLocationsInWorld)\n",
    "        locationRewardValue = [self.valueOfReward if location == 1 else 0.0 for location in world]\n",
    "        locationNonRewardCost = [-abs(self.costOfNonReward) if location == 0 else 0.0 for location in world]\n",
    "\n",
    "        totalLocationValue = [sum((costAct,costNoReward,valueReward)) for costAct, costNoReward, valueReward in zip(locationActionCost, locationNonRewardCost, locationRewardValue)]\n",
    "        utilityOfAction = [actionValue if action == 1 else 0 for actionValue, action in zip(totalLocationValue,action)]\n",
    "        return(sum(utilityOfAction))\n",
    "\n",
    "    def getLocationCostList(self, numberLocations):\n",
    "        if isinstance(self.costOfLocation, int) or isinstance(self.costOfLocation, float):\n",
    "            locationCost = [-abs(self.costOfLocation)]*numberLocations\n",
    "        else:\n",
    "            assert len(self.costOfLocation) == numberLocations, \"Location cost must be either an int/float or iterable of world length\"\n",
    "            locationCost = [-abs(locCost) for locCost in self.costOfLocation]\n",
    "        return(locationCost)\n",
    "\n",
    "# Grosse action utility - multiple agent actions\n",
    "\"\"\"\n",
    "    costOfLocation: list of dictionaries: list indices indicate agents [signaler, receiver], dictionaries indicate cost of actions {action key: action cost scalar}\n",
    "    valueOfReward: scalar reward value for achieving each component of the intended goal\n",
    "    nullAction: the representation of a null action (default = 'n')\n",
    "\"\"\"\n",
    "class ActionUtility_Grosse(object):\n",
    "    def __init__(self, costOfLocation, valueOfReward, nullAction = 'n'):\n",
    "        self.costOfLocation = costOfLocation\n",
    "        self.valueOfReward = valueOfReward\n",
    "        self.nullAction = nullAction\n",
    "\n",
    "    def __call__(self, action, world, goal):\n",
    "        assert self.isActionCongruous(action, world), 'action is not possible in this world'\n",
    "        jointCost  = self.getActionCost(action)\n",
    "        rewardAmount = self.getReward(action, goal)\n",
    "        totalUtility = jointCost + rewardAmount\n",
    "        return(totalUtility)\n",
    "            \n",
    "    def isActionCongruous(self, action, world):\n",
    "        areActionsPossible = [agentAction in world for agentAction in action if agentAction != self.nullAction]\n",
    "        return(all(areActionsPossible))\n",
    "    \n",
    "    #joint cost of action for all agents\n",
    "    def getActionCost(self, action):\n",
    "        signalerAction = action[0]\n",
    "        signalerCost = -abs(self.costOfLocation[0][signalerAction])\n",
    "        receiverAction = action[1]\n",
    "        receiverCost = -abs(self.costOfLocation[1][receiverAction])\n",
    "        jointActionCost = signalerCost + receiverCost\n",
    "        return(jointActionCost)\n",
    "\n",
    "    #total reward of action\n",
    "    def getReward(self, action, goal):\n",
    "        if goal == 'n':\n",
    "            return(0)\n",
    "        if goal == 'any':\n",
    "            print('any battery')\n",
    "\n",
    "        goalList = list(goal)\n",
    "        reward = 0\n",
    "        signalerAction = action[0]\n",
    "        receiverAction = action[1]\n",
    "        \n",
    "        if signalerAction in goalList:\n",
    "            reward += self.valueOfReward\n",
    "            goalList.remove(signalerAction)\n",
    "        if receiverAction in goalList:\n",
    "            reward += self.valueOfReward\n",
    "            goalList.remove(receiverAction)\n",
    "        return(reward)\n",
    "\n",
    "\"\"\"\n",
    "    pass in a signal and outout the scalar cost of that signal \n",
    "    based on how many token/pieces of information used to convey that signal and their respective costs\n",
    "    default signal marker (indication of a signal in a location) = 1\n",
    "    default null signal marker (indication of no signal in a location ) = 0\n",
    "\"\"\"\n",
    "class SignalCost_Misyak(object):\n",
    "    def __init__(self, signalCosts, signalMarker = 1, nullMarker = 0):\n",
    "        self.signalCosts = signalCosts\n",
    "        self.signalMarker = signalMarker\n",
    "        self.nullMarker = nullMarker\n",
    "\n",
    "    def __call__(self, signal):\n",
    "        assert (signal.count(self.signalMarker) + signal.count(self.nullMarker))== len(signal), \"signal contains undefined signal at some location\"\n",
    "\n",
    "        if isinstance(self.signalCosts, int) or isinstance(self.signalCosts, float):\n",
    "            numberOfTokensUsed = signal.count(self.signalMarker)\n",
    "            totalSignalCost = -abs(self.signalCosts)*numberOfTokensUsed\n",
    "        else:\n",
    "            totalSignalCost = sum([-abs(locCost) for locSignal, locCost in zip(signal, self.signalCosts) if locSignal == self.signalMarker])\n",
    "        return(totalSignalCost)\n",
    "\n",
    "\"\"\"\n",
    "    constructed with a function defining costs and another for action utility.\n",
    "    Takes in a signal and a pandas dataframe row with indices defining components of the mind\n",
    "    Outputs the sinal utility as c(signal) + u(action) = cost(signal) + cost(action, world) + reward(action, world, goal)\n",
    "\"\"\"\n",
    "class SignalUtility(object):\n",
    "    def __init__(self, signalCostFunction, actionUtilityFunction):\n",
    "        self.getSignalCost = signalCostFunction\n",
    "        self.getActionUtility = actionUtilityFunction\n",
    "\n",
    "    def __call__(self, signal, mind):\n",
    "        action = mind.index.get_level_values('actions')[0]\n",
    "        world =  mind.index.get_level_values('worlds')[0]\n",
    "        goal =  mind.index.get_level_values('goals')[0]\n",
    "        actionUtility = self.getActionUtility(action, world, goal)\n",
    "\n",
    "        signalCost = self.getSignalCost(signal)\n",
    "        signalUtility = actionUtility + signalCost\n",
    "        return(signalUtility)\n",
    "\n",
    "\n",
    "#p(a|w,g) component of the mind - Misyak\n",
    "\"\"\"\n",
    "    alpha: scalar rationality constant\n",
    "    actionUtilityFunction: function that takes in (action, world, goal) and returns a scalar utlity\n",
    "    softmax: boolean; False indicates strict maximization\n",
    "\"\"\"\n",
    "class ActionDistributionGivenWorldGoal(object):\n",
    "    def __init__(self, alpha, actionUtilityFunction, softmax=False):\n",
    "        self.alpha = alpha\n",
    "        self.getUtilityOfAction = actionUtilityFunction\n",
    "        self.softmax = softmax\n",
    "        \n",
    "    def __call__(self, actionSpace, world, goal):\n",
    "    \t#create a dataframe with indices actions\n",
    "        actionSpaceDF = getMultiIndexMindSpace({'actions':actionSpace})\n",
    "\n",
    "        #for each action, get the utility given goal, world; transform this into an action distribution\n",
    "        getConditionActionUtility = lambda x: np.exp(self.alpha*self.getUtilityOfAction(x.index.get_level_values(\"actions\")[0], world))\n",
    "        utilities = actionSpaceDF.groupby(actionSpaceDF.index.names).apply(getConditionActionUtility)\n",
    "    \n",
    "    \t#keep as softmax pdf or transform to strict maximization, normalize\n",
    "        if self.softmax:         \n",
    "            probabilities = normalizeValuesPdSeries(utilities)\n",
    "        else:\n",
    "            maxUtility = max(utilities)\n",
    "            numberOfOccurances = utilities.value_counts().loc[maxUtility]\n",
    "            getConditionProbability = lambda x: 1.0/numberOfOccurances if x == maxUtility else 0 \n",
    "            probabilities = utilities.apply(getConditionProbability)\n",
    "        \n",
    "        actionSpaceDF['p(a|w,g)'] = actionSpaceDF.index.get_level_values(0).map(probabilities.get)\n",
    "        return(actionSpaceDF)\n",
    "\n",
    "#p(a|w,g) component of the mind - Grosse\n",
    "\"\"\"\n",
    "    alpha: scalar rationality constant\n",
    "    actionUtilityFunction: function that takes in (action, world, goal) and returns a scalar utlity\n",
    "    softmax: boolean; False indicates strict maximization\n",
    "\"\"\"\n",
    "# Inputs in the callable: actions as tuples indicating agent actions; i.e. (signaler action, receiver action)\n",
    "class ActionDistributionGivenWorldGoal_Grosse(object):\n",
    "    def __init__(self, alpha, actionUtilityFunction, softmax=False):\n",
    "        self.alpha = alpha\n",
    "        self.getUtilityOfAction = actionUtilityFunction\n",
    "        self.softmax = softmax\n",
    "        \n",
    "    def __call__(self, actionSpace, world, goal):\n",
    "        #create a dataframe with indices actions\n",
    "        actionSpaceDF = getMultiIndexMindSpace({'actions':actionSpace})\n",
    "\n",
    "        #for each action, get the utility given goal, world; transform this into an action distribution\n",
    "        getConditionActionUtility = lambda x: np.exp(self.alpha*self.getUtilityOfAction(x.index.get_level_values('actions')[0], world, goal))\n",
    "        utilities = actionSpaceDF.groupby(actionSpaceDF.index.names).apply(getConditionActionUtility)\n",
    "        #keep as softmax pdf or transform to strict maximization\n",
    "        if self.softmax:         \n",
    "            probabilities = normalizeValuesPdSeries(utilities)\n",
    "        else:\n",
    "            maxUtility = max(utilities)\n",
    "            numberOfOccurances = utilities.value_counts().loc[maxUtility]\n",
    "            getConditionProbability = lambda x: 1.0/numberOfOccurances if x == maxUtility else 0 \n",
    "            probabilities = utilities.apply(getConditionProbability)\n",
    "            \n",
    "        actionSpaceDF['p(a|w,g)'] = actionSpaceDF.index.get_level_values(0).map(probabilities.get)\n",
    "        return(actionSpaceDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-08T23:34:55.528122Z",
     "start_time": "2019-10-08T23:34:55.517802Z"
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    signalSpace: list of all possible signals, inpit type must be valid pandas index\n",
    "    signalIsConsistent: function specifying whether the signal is logically consistent given a mind and signaler category\n",
    "\"\"\"\n",
    "class SignalerZero(object):\n",
    "    def __init__(self, signalSpace, signalIsConsistent, signalCostFunction=None, signalAlpha = 1):\n",
    "        self.signalSpace = signalSpace\n",
    "        self.signalIsConsistent = signalIsConsistent\n",
    "        self.getSignalCost = signalCostFunction\n",
    "        self.alpha = signalAlpha\n",
    "\n",
    "    def __call__(self, targetMind, signalerCategory): #p(signal|mind, category), for all signals in signal space\n",
    "        #create a dataframe that adds signal as an index to the target mind and a column labeled p(signal|mind,c)\n",
    "        likelihoodComponents = pd.DataFrame(data=np.inf,index=targetMind.index, columns=self.signalSpace).stack()\n",
    "        likelihoodComponents.index.names = targetMind.index.names + ['signals']\n",
    "        likelihoodComponents.name = 'p(signal|mind,c)'\n",
    "\n",
    "        #for each condition apply the get likelihood function, returns a distribution\n",
    "        signalLikelihoods = likelihoodComponents.groupby(likelihoodComponents.index.names).apply(self.getSignalLikelihoodGivenMind, signalerType = signalerCategory)\n",
    "        print('unnorm signals', signalLikelihoods)\n",
    "        normalizer = signalLikelihoods.sum(axis=0)\n",
    "        signalLikelihoods = signalLikelihoods.groupby(likelihoodComponents.index.names).apply(lambda x: x/normalizer)\n",
    "        return(pd.DataFrame(signalLikelihoods))\n",
    "\n",
    "    def getSignalLikelihoodGivenMind(self, signalingCondition, signalerType):\n",
    "        world = signalingCondition.index.get_level_values('worlds')[0]\n",
    "        desire = signalingCondition.index.get_level_values('desires')[0]\n",
    "        goal = signalingCondition.index.get_level_values('goals')[0]\n",
    "        action = signalingCondition.index.get_level_values('actions')[0]\n",
    "        mind = {'worlds': world, 'desires':desire, 'goals':goal, 'actions':action}\n",
    "\n",
    "        #extract the world and signal from the index condition\n",
    "        signal = signalingCondition.index.get_level_values('signals')[0]\n",
    "        \n",
    "        #check if signal is consistent with signaler type and mind, if so return 1/size of possible consisent signals\n",
    "        if self.signalIsConsistent(signal, mind, signalerType) and (signal in self.signalSpace):\n",
    "            possibleSignals = [s for s in self.signalSpace if self.signalIsConsistent(s, mind, signalerType)]\n",
    "            unifSignalProbability = 1.0/len(possibleSignals)\n",
    "            mindDF = self.getMindDF(mind)\n",
    "\n",
    "            utilityOfSignal = np.exp(self.alpha*self.getConditionSignalUtility(signal, mindDF))\n",
    "            #utilityNormalizingConstant = sum([np.exp(self.alpha*self.getConditionSignalUtility(s,mindDF)) for s in possibleSignals])\n",
    "            #normalizedUtility = np.exp(self.alpha*utilityOfSignal)/utilityNormalizingConstant\n",
    "            #print(\"signal Utility\", utilityOfSignal, \"\\n z\", utilityNormalizingConstant, \"\\n final U\", normalizedUtility, \"\\n\")\n",
    "            return(utilityOfSignal)\n",
    "        return(0.0)\n",
    "\n",
    "    def getMindDF(self, mindDictionary):\n",
    "        mindLabels = list(mindDictionary.keys())\n",
    "        mindValues = [[v] for v in mindDictionary.values()]\n",
    "        idx = pd.MultiIndex.from_product(mindValues, names=mindLabels)\n",
    "        mindCondition = pd.DataFrame(index=idx)\n",
    "        return(mindCondition)\n",
    "\n",
    "    def getConditionSignalUtility(self, signal, mindcondition):\n",
    "        if self.getSignalCost is None:\n",
    "            return(0)\n",
    "        return(self.getSignalCost(signal, mindcondition))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-08T23:34:57.530859Z",
     "start_time": "2019-10-08T23:34:57.519961Z"
    }
   },
   "outputs": [],
   "source": [
    "class ReceiverZero(object):\n",
    "    def __init__(self, commonGroundDictionary, constructMind, getSignalerZero, signalCategoryPrior):\n",
    "        self.mindPrior = constructMind(commonGroundDictionary)\n",
    "        self.getSignalLikelihood = getSignalerZero\n",
    "        self.signalCategoryPrior = signalCategoryPrior\n",
    "\n",
    "        #index and column names for dataframe\n",
    "        self.mindLabels = list(commonGroundDictionary.keys())\n",
    "        self.signalerTypeLabel = 'signalerType' \n",
    "        self.signalLabel = 'signals'\n",
    "        self.pMindLabel, self.pCatLabel, self.pJointLabel, self.pLikekihoodLabel, self.pPosteriorLabel = ['p(mind)','p(c)', 'p(mind,c)', 'p(signal|mind,c)', 'p(mind|signal)']\n",
    "\n",
    "    def __call__(self, signal):\n",
    "        mindAndCategoryPrior = self.constructJointMindSignalCategoryPrior(self.mindPrior, self.signalCategoryPrior)\n",
    "        print(\"mind/cat prior\", mindAndCategoryPrior, \"\\n\")\n",
    "        likelihoodDF = self.constructLikelihoodDataFrameFromMindConditions(self.mindPrior)\n",
    "        print(\"lik\", likelihoodDF, \"\\n\")\n",
    "        mindPosterior = self.getMindPosterior(mindAndCategoryPrior, likelihoodDF, signal)\n",
    "        print('posterior', mindPosterior, '\\n')\n",
    "        return(mindPosterior)\n",
    "\n",
    "    def constructLikelihoodDataFrameFromMindConditions(self, mindPrior):\n",
    "        categoryNames = list(self.signalCategoryPrior.keys())\n",
    "\n",
    "        # find the signal likelihood distribution for each signaler type and concatenate dataframes into a single pandas DF distribution\n",
    "        likelihoodByCategory = [self.getSignalLikelihood(mindPrior, signalerType) for signalerType in categoryNames]\n",
    "        likelihoodDistributionList =  [pd.concat([likelihoodDist], keys=[categoryName], names=[self.signalerTypeLabel]) for likelihoodDist, categoryName in zip(likelihoodByCategory, categoryNames)]\n",
    "        likelihoodDistributionDF = pd.concat(likelihoodDistributionList)\n",
    "\n",
    "        return(likelihoodDistributionDF)\n",
    "\n",
    "    def constructJointMindSignalCategoryPrior(self, mindPrior, categoryPrior):\n",
    "        #from signal category prior, create a pandas df with index as category type label and column of p(c) probability\n",
    "        categoryPriorDF = pd.DataFrame(list(categoryPrior.items()), columns=[self.signalerTypeLabel, self.pCatLabel])\n",
    "        categoryPriorDF.set_index(self.signalerTypeLabel, inplace=True)\n",
    "\n",
    "        #duplicate the mind prior * the number of possible signal type categories, set the index to the joint p(mind, c) combinations\n",
    "        categoryNames = list(categoryPrior.keys())\n",
    "        numberOfCategories = len(categoryNames)\n",
    "        mindCPrior = pd.concat([mindPrior]*numberOfCategories, keys=categoryNames, names=[self.signalerTypeLabel])\n",
    "\n",
    "        #merge the categoryPriorDF into the mindCPrior, take the product of p(mind)*p(c) columns and return the resulting column p(mind, c)\n",
    "        jointPrior = pd.merge(left=mindCPrior.reset_index(level=self.mindLabels),right=categoryPriorDF,on=[self.signalerTypeLabel])\n",
    "        jointPrior[self.pJointLabel] = jointPrior[self.pMindLabel] * jointPrior[self.pCatLabel]\n",
    "        jointPrior = jointPrior.set_index(self.mindLabels,append=True)[[self.pJointLabel]]\n",
    "\n",
    "        return(jointPrior)\n",
    "\n",
    "    def getMindPosterior(self, jointPrior, likelihood, signal):\n",
    "        #merge the prior and likelihood dataframes, take the product of p(mind,c)*p(signal|mind,c) and get the posterior distribution \n",
    "        posterior = pd.merge(left=jointPrior,right=likelihood.reset_index(level=[self.signalLabel]),on=[self.signalerTypeLabel]+self.mindLabels)\n",
    "        posterior[self.pPosteriorLabel] = posterior[self.pJointLabel] * posterior[self.pLikekihoodLabel]\n",
    "        posterior = posterior.set_index(posterior[self.signalLabel],append=True)[[self.pPosteriorLabel]]\n",
    "        posterior = posterior.reorder_levels([self.signalLabel,self.signalerTypeLabel]+self.mindLabels)\n",
    "\n",
    "        #extract the signal location, normalize, and integrate out the category type to get p(mind|signal)\n",
    "        mindAndCPosterior = posterior.loc[signal]\n",
    "        mindAndCPosterior[self.pPosteriorLabel] = mindAndCPosterior[self.pPosteriorLabel]/sum(mindAndCPosterior[self.pPosteriorLabel])\n",
    "        print(\"posterior before integration\", mindAndCPosterior, '\\n')\n",
    "        mindPosterior = mindAndCPosterior.groupby(level=self.mindLabels).sum()\n",
    "        return(mindPosterior)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-08T23:35:01.535193Z",
     "start_time": "2019-10-08T23:35:01.529211Z"
    }
   },
   "outputs": [],
   "source": [
    "class SignalerOne(object):\n",
    "    def __init__(self, alpha, signalSpace, getActionUtility, getReceiverZero, getSignalCost = None):\n",
    "        self.alpha = alpha\n",
    "        self.signalSpace = signalSpace\n",
    "        self.getActionUtility = getActionUtility\n",
    "        self.getReceiverZero = getReceiverZero\n",
    "        self.getSignalCost = getSignalCost\n",
    "\n",
    "    def __call__(self, observation):\n",
    "        signalSpaceDF = getMultiIndexMindSpace({'signals': self.signalSpace})\n",
    "\n",
    "        #get the signal utility for each signal with respect to the observation from environment\n",
    "        getConditionUtility = lambda x: np.exp(self.alpha*self.getUtilityofSignal(observation, x.index.get_level_values('signals')[0]))\n",
    "        utilities = signalSpaceDF.groupby(signalSpaceDF.index.names).apply(getConditionUtility)\n",
    "        \n",
    "        #normalize probabilities and return as a pd DF column\n",
    "        sumOfUtilities = sum(utilities)\n",
    "        probabilities = utilities.groupby(utilities.index.names).apply(lambda x: x/sumOfUtilities)\n",
    "        signalSpaceDF['probabilities'] = signalSpaceDF.index.get_level_values(0).map(probabilities.get)\n",
    "        return(signalSpaceDF)  \n",
    "\n",
    "    def getUtilityofSignal(self, observation, signal):\n",
    "        #determine which mind components are observed\n",
    "        if 'goals' in observation.keys():\n",
    "            goal = observation['goals']\n",
    "        else:\n",
    "            goal = None\n",
    "\n",
    "        if 'worlds' in observation.keys():\n",
    "            world = observation['worlds']\n",
    "        else:\n",
    "            world = None\n",
    "\n",
    "        #get the posterior of the mind, sum across all possible minds to get a distribution of actions\n",
    "        mindPosterior = self.getReceiverZero(signal)\n",
    "        actionPosterior = pd.DataFrame(mindPosterior.groupby(level=['actions']).sum())\n",
    "\n",
    "        #find the action utilities and evaluate with respect to information from the speaker (observation) E_a[U(mind_speaker, a)|signal]\n",
    "        getConditionActionUtility = lambda x: self.getActionUtility(x.index.get_level_values('actions')[0], world, goal)\n",
    "        actionPosterior['utility'] = actionPosterior.groupby(actionPosterior.index.names).apply(getConditionActionUtility)\n",
    "        expectedSignalReward = sum(actionPosterior['p(mind|signal)']*actionPosterior['utility'])\n",
    "        #signal cost\n",
    "        signalCost = -abs(self.getCostOfSignalFromFunction(signal))\n",
    "\n",
    "        totalUtility =  expectedSignalReward + signalCost\n",
    "        return(totalUtility)\n",
    "\n",
    "    def getCostOfSignalFromFunction(self, signal):\n",
    "        if self.getSignalCost is None:\n",
    "            return(0)\n",
    "        return(self.getSignalCost(signal))\n",
    "\n",
    "\n",
    "# idea is to treat the action posterior p(a|signal) as an input\n",
    "# new inputs of signaler 1 should be p(a|signal) function, utility of action function\n",
    "class ActionDistributionForSignal(object):\n",
    "    def __init__(self, receiverZeroFunction, actionUtilityFunction, actionSpace):\n",
    "        pass\n",
    "    def __call__(self, signal):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-08T23:50:17.566909Z",
     "start_time": "2019-10-08T23:50:17.559596Z"
    }
   },
   "outputs": [],
   "source": [
    "#world spaces\n",
    "twoRewardWorldSpace = getWorldSpace(wall = False, nBoxes = 3, nRewards = 2)\n",
    "oneRewardWorldSpace = getWorldSpace(wall = False, nBoxes = 3, nRewards = 1)\n",
    "wallWorldSpace = getWorldSpace(wall = True, nBoxes = 3, nRewards = 2)\n",
    "\n",
    "#action spaces\n",
    "oneAxeActionSpace = getActionSpace(nBoxes = 3, nReceiverChoices = 1)\n",
    "#oneAxeActionSpace.remove((0,0,0))\n",
    "twoAxeActionSpace = getActionSpace(nBoxes = 3, nReceiverChoices = 2)\n",
    "#twoAxeActionSpace.remove((0,0,0))\n",
    "\n",
    "#signal spaces\n",
    "oneTokenSignalSpace = getSignalSpace(nBoxes=3, nSignals = 1)\n",
    "#oneTokenSignalSpace.remove((0,0,0))\n",
    "twoTokenSignalSpace = getSignalSpace(nBoxes=3, nSignals = 2)\n",
    "#twoTokenSignalSpace.remove((0,0,0))\n",
    "\n",
    "#condition common ground spaces\n",
    "twoTokenCondition = {'worlds': twoRewardWorldSpace, 'desires': [1], 'goals': [1], 'actions': twoAxeActionSpace}\n",
    "inversionCondition = {'worlds': twoRewardWorldSpace, 'desires': [1], 'goals': [1], 'actions': twoAxeActionSpace}\n",
    "oneAxeCondition = {'worlds': twoRewardWorldSpace, 'desires': [1], 'goals': [1], 'actions': oneAxeActionSpace}\n",
    "wallCondition = {'worlds': wallWorldSpace, 'desires': [1], 'goals': [1], 'actions': twoAxeActionSpace}\n",
    "\n",
    "oneTokenCondition = {'worlds': oneRewardWorldSpace, 'desires': [1], 'goals': [1], 'actions': oneAxeActionSpace}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-08T23:37:19.812833Z",
     "start_time": "2019-10-08T23:37:19.807207Z"
    }
   },
   "outputs": [],
   "source": [
    "#parameters consistent across conditions\n",
    "a = 4\n",
    "signalCategoryPrior = {'1':.57, '-1':.43}\n",
    "getActionUtility = ActionUtility(costOfLocation=0,\n",
    "                                 costOfNonReward=0,\n",
    "                                 valueOfReward=5)\n",
    "getActionDistribution = ActionDistributionGivenWorldGoal(a, getActionUtility, False)\n",
    "getMind = GenerateMind(getWorldProbabiltiy_Uniform, getDesireProbability_Uniform, getGoalGivenWorldAndDesire_SingleGoal, getActionDistribution)\n",
    "signalCost = 0.0\n",
    "getSignalCost = SignalCost_Misyak(signalCost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-08T23:37:48.449791Z",
     "start_time": "2019-10-08T23:37:48.137087Z"
    }
   },
   "outputs": [],
   "source": [
    "getGenerativeSignaler_2Token = SignalerZero(twoTokenSignalSpace, signalIsConsistent_Boxes)\n",
    "getReceiverZero_2Token = ReceiverZero(commonGroundDictionary=twoTokenCondition, constructMind=getMind, getSignalerZero=getGenerativeSignaler_2Token, signalCategoryPrior=signalCategoryPrior)\n",
    "getSignalerOne_2Token = SignalerOne(alpha=a, signalSpace =twoTokenSignalSpace,  getActionUtility=getActionUtility, getReceiverZero=getReceiverZero_2Token, getSignalCost=getSignalCost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-08T23:37:55.118803Z",
     "start_time": "2019-10-08T23:37:51.211833Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "observedWorld = {'worlds':(1,1,0)}\n",
    "getSignalerOne_2Token(observedWorld)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-08T23:51:44.822127Z",
     "start_time": "2019-10-08T23:51:44.768501Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>p(mind)</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>worlds</th>\n",
       "      <th>desires</th>\n",
       "      <th>goals</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>(0, 1, 1)</th>\n",
       "      <th>1</th>\n",
       "      <th>1</th>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(1, 0, 1)</th>\n",
       "      <th>1</th>\n",
       "      <th>1</th>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(1, 1, 0)</th>\n",
       "      <th>1</th>\n",
       "      <th>1</th>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          p(mind)\n",
       "worlds    desires goals          \n",
       "(0, 1, 1) 1       1      0.333333\n",
       "(1, 0, 1) 1       1      0.333333\n",
       "(1, 1, 0) 1       1      0.333333"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "twoTokenMind = {'worlds': twoRewardWorldSpace, 'desires': [1], 'goals': [1]}\n",
    "getMind = GenerateMind(getWorldProbabiltiy_Uniform, getDesireProbability_Uniform, getGoalGivenWorldAndDesire_SingleGoal)\n",
    "getMind(twoTokenMind)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-09T22:08:14.902670Z",
     "start_time": "2019-10-09T22:08:14.895237Z"
    }
   },
   "outputs": [],
   "source": [
    "import itertools\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.patches import Rectangle\n",
    "\n",
    "gridWidth = 5\n",
    "gridHeight = 5\n",
    "states = list(itertools.product(range(gridWidth), range(gridHeight)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-09T22:11:00.432299Z",
     "start_time": "2019-10-09T22:11:00.424840Z"
    }
   },
   "outputs": [],
   "source": [
    "def visualizeEnvironmentByState(states, goalStates = [], trapStates = [], trajectory = [], goalNameDictionary = {}):\n",
    "    gridAdjust = .5\n",
    "    gridScale = 1.5\n",
    "\n",
    "    minimumx, minimumy = [min(coord) for coord in zip(*states)]\n",
    "    maximumx, maximumy = [max(coord) for coord in zip(*states)]\n",
    "    \n",
    "    plt.rcParams[\"figure.figsize\"] = [(maximumx-minimumx)*gridScale, (maximumy-minimumy)*gridScale]\n",
    "    ax = plt.gca(frameon=False, xticks = range(minimumx-1, maximumx+2), yticks = range(minimumy-1, maximumy+2))\n",
    "\n",
    "    #gridline drawing\n",
    "    for (statex, statey) in states:\n",
    "        ax.add_patch(Rectangle((statex-gridAdjust, statey-gridAdjust), 1, 1, fill=False, color='black', alpha=1))\n",
    "\n",
    "    #goal coloring and labeling\n",
    "    for (goalx,goaly) in goalStates:\n",
    "        ax.add_patch(Rectangle((goalx-gridAdjust, goaly-gridAdjust), 1, 1, fill=True, color='green', alpha=.5))\n",
    "        if (goalx, goaly) in goalNameDictionary.keys():\n",
    "            ax.text(goalx-.15, goaly-.3, goalNameDictionary[(goalx, goaly)], fontsize = 35)\n",
    "\n",
    "    for (trapx, trapy) in trapStates:\n",
    "        ax.add_patch(Rectangle((trapx-gridAdjust, trapy-gridAdjust), 1, 1, fill=True, color='red', alpha=.1))\n",
    "        if (trapx, trapy) in goalNameDictionary.keys():\n",
    "            ax.text(trapx-.15, trapy-.3, goalNameDictionary[(trapx, trapy)], fontsize = 35)\n",
    "\n",
    "    #trajectory path coloring\n",
    "    for indx, (statex, statey) in enumerate(trajectory):\n",
    "        ax.add_patch(Rectangle((statex-gridAdjust, statey-gridAdjust), 1, 1, fill=True, color='blue', alpha=.1))\n",
    "        ax.text(statex-.1, statey-.1, str(indx), fontsize = 20)\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-09T22:11:01.368286Z",
     "start_time": "2019-10-09T22:11:01.262803Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "visualizeEnvironmentByState(states, [(2,0), (4,2), (0,2)],[(2,4)],[],{(2,4):'1', (4,2):'2', (2,0): '3',(0,2):'4'})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
